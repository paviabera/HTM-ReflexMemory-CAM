{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from htm.bindings.sdr import SDR, Metrics\n",
    "from htm.encoders.scalar_encoder import ScalarEncoder, ScalarEncoderParameters\n",
    "from htm.encoders.date import DateEncoder\n",
    "from htm.algorithms import SpatialPooler\n",
    "from htm.bindings.algorithms import TemporalMemory\n",
    "from htm.algorithms.anomaly_likelihood import AnomalyLikelihood\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import datetime\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflexiveMemory:\n",
    "  def __init__(self, dimensions):\n",
    "    self.previous_sdr = None\n",
    "    self.pairs = {}\n",
    "    self.dimensions = dimensions\n",
    "\n",
    "  def add(self, sdr):\n",
    "    current_sdr = '-'.join(map(str, sdr.sparse))\n",
    "    if(self.previous_sdr != None):\n",
    "      values = self.pairs.get(self.previous_sdr, {})\n",
    "      pair_count = values.get(current_sdr, 0)\n",
    "      pair_count = pair_count + 1\n",
    "      if self.pairs.get(self.previous_sdr, None) is None:\n",
    "        self.pairs[self.previous_sdr] = { current_sdr: pair_count }\n",
    "      else:\n",
    "        self.pairs[self.previous_sdr][current_sdr] = pair_count\n",
    "    self.previous_sdr = current_sdr\n",
    "\n",
    "  def predict(self, sdr):\n",
    "    search_sdr = '-'.join(map(str, sdr.sparse))\n",
    "    values = self.pairs.get(search_sdr, {})\n",
    "    return_value = 0\n",
    "    return_key = None\n",
    "    for key, value in values.items():\n",
    "      if value > return_value:\n",
    "        return_value = value\n",
    "        return_key = key\n",
    "    if return_key is not None:\n",
    "      return_sdr = SDR( self.dimensions )\n",
    "      return_sdr.sparse = list(map(int, return_key.split('-')))\n",
    "      return_key = return_sdr\n",
    "    return return_value, return_key\n",
    "\n",
    "  # Control Unit\n",
    "  def learn(self, sdr):\n",
    "    pred_correct = False\n",
    "    pred_anomaly = None\n",
    "    if self.previous_sdr is not None:\n",
    "        prev_activeColumns = SDR( self.dimensions )\n",
    "        prev_activeColumns.sparse = list(map(int, self.previous_sdr.split('-')))\n",
    "\n",
    "        pred_value, pred_key = self.predict(prev_activeColumns)\n",
    "        if pred_key is not None:\n",
    "            if pred_key.flatten() == sdr.flatten():\n",
    "                pred_correct = True\n",
    "                pred_anomaly = 0\n",
    "            else:\n",
    "                key1 = self.previous_sdr\n",
    "                key2 = '-'.join(map(str, pred_key.sparse))\n",
    "                self.pairs[key1][key2] = pred_value - 1\n",
    "                \n",
    "                pred_anomaly = 1 - np.count_nonzero((pred_key.dense & sdr.dense)) / np.count_nonzero(sdr.dense)\n",
    "\n",
    "    return pred_correct, pred_anomaly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSources = [\n",
    "    \"hourly_numentaTM_speed_7578.csv\",\n",
    "    \"hourly_numentaTM_iio_us-east-1_i-a2eb1cd9_NetworkIn.csv\",\n",
    "    \"hourly_numentaTM_exchange-3_cpc_results.csv\",\n",
    "    \"hourly_numentaTM_exchange-3_cpm_results.csv\",\n",
    "    \"hourly_numentaTM_exchange-2_cpc_results.csv\",\n",
    "    \"hourly_numentaTM_exchange-2_cpm_results.csv\",\n",
    "    \"hourly_numentaTM_exchange-4_cpc_results.csv\",\n",
    "    \"hourly_numentaTM_exchange-4_cpm_results.csv\",\n",
    "    \"hourly_numentaTM_rogue_agent_key_hold.csv\",\n",
    "    \"hourly_numentaTM_TravelTime_451.csv\",\n",
    "    \"hourly_numentaTM_occupancy_6005.csv\",\n",
    "    \"hourly_numentaTM_speed_t4013.csv\",\n",
    "    \"hourly_numentaTM_TravelTime_387.csv\",\n",
    "    \"hourly_numentaTM_occupancy_t4013.csv\",\n",
    "    \"hourly_numentaTM_speed_6005.csv\",\n",
    "    \"hourly_numentaTM_art_daily_flatmiddle.csv\",\n",
    "    \"hourly_numentaTM_art_daily_jumpsdown.csv\",\n",
    "    \"hourly_numentaTM_art_daily_jumpsup.csv\",\n",
    "    \"hourly_numentaTM_art_daily_no_noise.csv\",\n",
    "    \"hourly_numentaTM_art_daily_nojump.csv\",\n",
    "    \"hourly_numentaTM_art_daily_perfect_square_wave.csv\",\n",
    "    \"hourly_numentaTM_art_daily_small_noise.csv\",\n",
    "    \"hourly_numentaTM_art_flatline.csv\",\n",
    "    \"hourly_numentaTM_art_increase_spike_density.csv\",\n",
    "    \"hourly_numentaTM_art_load_balancer_spikes.csv\",\n",
    "    \"hourly_numentaTM_art_noisy.csv\",\n",
    "    \"hourly_numentaTM_ec2_cpu_utilization_24ae8d.csv\",\n",
    "    \"hourly_numentaTM_ec2_cpu_utilization_53ea38.csv\",\n",
    "    \"hourly_numentaTM_ec2_cpu_utilization_5f5533.csv\",\n",
    "    \"hourly_numentaTM_ec2_cpu_utilization_77c1ca.csv\",\n",
    "    \"hourly_numentaTM_ec2_cpu_utilization_825cc2.csv\",\n",
    "    \"hourly_numentaTM_ec2_cpu_utilization_ac20cd.csv\",\n",
    "    \"hourly_numentaTM_ec2_cpu_utilization_c6585a.csv\",\n",
    "    \"hourly_numentaTM_ec2_cpu_utilization_fe7f93.csv\",\n",
    "    \"hourly_numentaTM_ec2_disk_write_bytes_c0d644.csv\",\n",
    "    \"hourly_numentaTM_ec2_network_in_257a54.csv\",\n",
    "    \"hourly_numentaTM_ec2_request_latency_system_failure.csv\",\n",
    "    \"hourly_numentaTM_elb_request_count_8c0756.csv\",\n",
    "    \"hourly_numentaTM_rds_cpu_utilization_cc0c53.csv\",\n",
    "    \"hourly_numentaTM_rds_cpu_utilization_e47b3b.csv\",\n",
    "    \"hourly_numentaTM_grok_asg_anomaly.csv\",\n",
    "    \"hourly_numentaTM_ec2_disk_write_bytes_1ef3de.csv\",\n",
    "    \"hourly_numentaTM_ec2_network_in_5abac7.csv\",\n",
    "    \"hourly_numentaTM_rogue_agent_key_updown.csv\",\n",
    "    \"hourly_numentaTM_ambient_temperature_system_failure.csv\",\n",
    "    \"hourly_numentaTM_nyc_taxi.csv\",\n",
    "    \"hourly_numentaTM_Twitter_volume_AMZN.csv\",\n",
    "    \"hourly_numentaTM_Twitter_volume_FB.csv\",\n",
    "    \"hourly_numentaTM_Twitter_volume_GOOG.csv\",\n",
    "    \"hourly_numentaTM_Twitter_volume_KO.csv\",\n",
    "    \"hourly_numentaTM_Twitter_volume_CVS.csv\",\n",
    "    \"hourly_numentaTM_Twitter_volume_PFE.csv\",\n",
    "    \"hourly_numentaTM_Twitter_volume_UPS.csv\",\n",
    "    \"hourly_numentaTM_Twitter_volume_IBM.csv\",\n",
    "    \"hourly_numentaTM_Twitter_volume_AAPL.csv\",\n",
    "    \"hourly_numentaTM_Twitter_volume_CRM.csv\",\n",
    "    \"hourly_numentaTM_cpu_utilization_asg_misconfiguration.csv\",\n",
    "    \"hourly_numentaTM_machine_temperature_system_failure.csv\",\n",
    "#    \"value1_pseudo_periodic_synthetic_1.csv\",\n",
    "#    \"value1_pseudo_periodic_synthetic_2.csv\",\n",
    "#    \"value1_pseudo_periodic_synthetic_3.csv\",\n",
    "#    \"value1_pseudo_periodic_synthetic_4.csv\",\n",
    "#    \"value1_pseudo_periodic_synthetic_5.csv\",\n",
    "#    \"value1_pseudo_periodic_synthetic_6.csv\",\n",
    "#    \"value1_pseudo_periodic_synthetic_7.csv\",\n",
    "#    \"value1_pseudo_periodic_synthetic_8.csv\",\n",
    "#    \"value1_pseudo_periodic_synthetic_9.csv\",\n",
    "#    \"value1_pseudo_periodic_synthetic_10.csv\",\n",
    "#    \"monthly_gold_prices.csv\",\n",
    "#    \"monthly_sp500.csv\",\n",
    "#    \"weekly_dow_jones.csv\",\n",
    "#    \"weekly_nasdaq.csv\",\n",
    "#    \"weekly_sp500.csv\",\n",
    "#    \"monthly_vix_close.csv\",\n",
    "#    \"monthly_vix_high.csv\",\n",
    "#    \"monthly_vix_low.csv\",\n",
    "#    \"monthly_vix_open.csv\",\n",
    "#    \"daily_natural_gas.csv\",\n",
    "#    \"daily_oil_prices.csv\",\n",
    "#    \"value1_vix_close.csv\",\n",
    "#    \"value1_vix_high.csv\",\n",
    "#    \"value1_vix_low.csv\",\n",
    "#    \"value1_vix_open.csv\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    'enc': {\n",
    "        \"value\" :\n",
    "            {'size': 700, 'activeBits': 41, 'minimum': None, 'maximum': None},\n",
    "        \"time\": \n",
    "            {'timeOfDay': (30, 1), 'weekend': 21}\n",
    "    },\n",
    "    'sp': {\n",
    "        'inputDimensions': None,\n",
    "        'columnDimensions': (1638,),\n",
    "        'potentialPct': 0.85,\n",
    "        'potentialRadius': None,\n",
    "        'globalInhibition': True,\n",
    "        'localAreaDensity': 0.04395604395604396,\n",
    "        'synPermInactiveDec': 0.006,\n",
    "        'synPermActiveInc': 0.04,\n",
    "        'synPermConnected': 0.13999999999999999,\n",
    "        'boostStrength': 3.0,\n",
    "        'wrapAround': True,\n",
    "        'seed': 1,\n",
    "        'learn': False,\n",
    "    },\n",
    "    'tm': {\n",
    "        'cellsPerColumn': 13,\n",
    "        'activationThreshold': 17,\n",
    "        'initialPermanence': 0.21,\n",
    "        'minThreshold': 10,\n",
    "        'maxNewSynapseCount': 32,\n",
    "        'permanenceIncrement': 0.1,\n",
    "        'permanenceDecrement': 0.1,\n",
    "        'predictedSegmentDecrement': 0.0,\n",
    "        'maxSegmentsPerCell': 128,\n",
    "        'maxSynapsesPerSegment': 64,\n",
    "        'learn': True\n",
    "    },\n",
    "    'anomaly': {'period': 1000},\n",
    "    'learnRows': 100\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 1/58 [00:01<01:20,  1.41s/it]\n"
     ]
    }
   ],
   "source": [
    "input_path = pathlib.Path('../datasets/numenta')\n",
    "\n",
    "pbar = tqdm(total=len(inputSources))\n",
    "for dataset in inputSources:\n",
    "\n",
    "    records = []\n",
    "    with open(input_path.joinpath(dataset), \"r\") as fin:\n",
    "        reader = csv.reader(fin)\n",
    "        headers = next(reader)\n",
    "        next(reader)\n",
    "        next(reader)\n",
    "        for record in reader:\n",
    "            records.append(record)\n",
    "    \n",
    "    dateEncoder = DateEncoder(\n",
    "        timeOfDay= config[\"enc\"][\"time\"][\"timeOfDay\"], \n",
    "        weekend  = config[\"enc\"][\"time\"][\"weekend\"]\n",
    "    )\n",
    "\n",
    "    config[\"enc\"][\"value\"][\"minimum\"] = min(float(r[1]) for r in records)\n",
    "    config[\"enc\"][\"value\"][\"maximum\"] = max(float(r[1]) for r in records)\n",
    "    \n",
    "    scalarEncoderParams = ScalarEncoderParameters()\n",
    "    scalarEncoderParams.activeBits = config[\"enc\"][\"value\"][\"activeBits\"]\n",
    "    scalarEncoderParams.minimum = config[\"enc\"][\"value\"][\"minimum\"]\n",
    "    scalarEncoderParams.maximum = config[\"enc\"][\"value\"][\"maximum\"]\n",
    "    scalarEncoderParams.size = config[\"enc\"][\"value\"][\"size\"]\n",
    "    scalarEncoder = ScalarEncoder( scalarEncoderParams )\n",
    "    # encodingWidth = (dateEncoder.size + scalarEncoder.size)\n",
    "    encodingWidth = (scalarEncoder.size)\n",
    "\n",
    "\n",
    "    config['sp']['inputDimensions'] = (encodingWidth,)\n",
    "    config['sp']['potentialRadius'] = encodingWidth\n",
    "\n",
    "    sp = SpatialPooler(\n",
    "        inputDimensions = config['sp']['inputDimensions'],\n",
    "        columnDimensions = config['sp']['columnDimensions'],\n",
    "        potentialPct = config['sp']['potentialPct'],\n",
    "        potentialRadius = config['sp']['potentialRadius'],\n",
    "        globalInhibition = config['sp']['globalInhibition'],\n",
    "        localAreaDensity = config['sp']['localAreaDensity'],\n",
    "        synPermInactiveDec = config['sp']['synPermInactiveDec'],\n",
    "        synPermActiveInc = config['sp']['synPermActiveInc'],\n",
    "        synPermConnected = config['sp']['synPermConnected'],\n",
    "        boostStrength = config['sp']['boostStrength'],\n",
    "        wrapAround = config['sp']['wrapAround'],\n",
    "        seed = config['sp']['seed']\n",
    "    )\n",
    "\n",
    "    tm = TemporalMemory(\n",
    "        columnDimensions = config['sp']['columnDimensions'],\n",
    "        cellsPerColumn = config['tm']['cellsPerColumn'],\n",
    "        activationThreshold = config['tm']['activationThreshold'],\n",
    "        initialPermanence = config['tm']['initialPermanence'],\n",
    "        connectedPermanence = config['sp']['synPermConnected'],\n",
    "        minThreshold = config['tm']['minThreshold'],\n",
    "        maxNewSynapseCount = config['tm']['maxNewSynapseCount'],\n",
    "        permanenceIncrement = config['tm']['permanenceIncrement'],\n",
    "        permanenceDecrement = config['tm']['permanenceDecrement'],\n",
    "        predictedSegmentDecrement = config['tm']['predictedSegmentDecrement'],\n",
    "        maxSegmentsPerCell = config['tm']['maxSegmentsPerCell'],\n",
    "        maxSynapsesPerSegment = config['tm']['maxSynapsesPerSegment']\n",
    "    )\n",
    "\n",
    "    rm = ReflexiveMemory( sp.getColumnDimensions() )\n",
    "\n",
    "    enc_info = Metrics( [encodingWidth], 999999999)\n",
    "    sp_info = Metrics( sp.getColumnDimensions(), 999999999 )\n",
    "    tm_info = Metrics( [tm.numberOfCells()], 999999999 )\n",
    "    anomaly_history = AnomalyLikelihood(config[\"anomaly\"][\"period\"])\n",
    "\n",
    "    inputs = []\n",
    "    anomaly = []\n",
    "    anomalyProb = []\n",
    "    anomalyRM = []\n",
    "    for count, record in enumerate(records):\n",
    "\n",
    "        dateString = datetime.datetime.strptime(record[0], \"%Y-%m-%d %H:%M:%S\")\n",
    "        consumption = float(record[1])\n",
    "        inputs.append( consumption )\n",
    "        \n",
    "        dateBits = dateEncoder.encode(dateString)\n",
    "        consumptionBits = scalarEncoder.encode(consumption)\n",
    "\n",
    "        # encoding = SDR( encodingWidth ).concatenate([consumptionBits, dateBits])\n",
    "        encoding = SDR( consumptionBits )\n",
    "        enc_info.addData( encoding )\n",
    "        \n",
    "        activeColumns = SDR( sp.getColumnDimensions() )\n",
    "        predictiveColumns = SDR( sp.getColumnDimensions() )\n",
    "\n",
    "        if count < config['learnRows']:\n",
    "\n",
    "            sp.compute(encoding, True, activeColumns)\n",
    "            sp_info.addData( activeColumns )\n",
    "\n",
    "            tm.compute(activeColumns, learn=True)\n",
    "            tm_info.addData( tm.getActiveCells().flatten() )\n",
    "\n",
    "        else: \n",
    "\n",
    "            sp.compute(encoding, config['sp']['learn'], activeColumns)\n",
    "            sp_info.addData( activeColumns )\n",
    "\n",
    "            pred_correct, pred_anomaly = rm.learn(activeColumns)\n",
    "            anomalyRM.append( pred_anomaly )\n",
    "            rm.add(activeColumns)\n",
    "\n",
    "            tm.compute(activeColumns, learn=config['tm']['learn'])\n",
    "            tm_info.addData( tm.getActiveCells().flatten() )\n",
    "\n",
    "            tm.activateDendrites(True)\n",
    "            predictiveColumns.sparse = list(set(sorted(list(np.where(tm.getPredictiveCells().dense == 1)[0]))))\n",
    "\n",
    "\n",
    "        anomaly.append( tm.anomaly )\n",
    "        anomalyProb.append( anomaly_history.compute(tm.anomaly) )\n",
    "\n",
    "    pbar.update(1)\n",
    "    break\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_119206/3384318560.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  activeColumns.sparse == predictiveColumns.sparse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = set(predictiveColumns.sparse)\n",
    "y = set(activeColumns.sparse)\n",
    "\n",
    "x == y\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
