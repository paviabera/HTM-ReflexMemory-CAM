{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from htm.bindings.sdr import SDR, Metrics\n",
    "from htm.encoders.date import DateEncoder\n",
    "from htm.algorithms import SpatialPooler\n",
    "from htm.bindings.algorithms import TemporalMemory\n",
    "from htm.algorithms.anomaly_likelihood import AnomalyLikelihood\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import datetime\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import os\n",
    "from htm.encoders.rdse import RDSE, RDSE_Parameters\n",
    "import time\n",
    "import traceback\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflexiveMemory:\n",
    "  def __init__(self, reflexSize):\n",
    "    self.acKey0 = None\n",
    "    self.pairs = {}\n",
    "    self.anomalyRM = []\n",
    "    self.anomalyTM = []\n",
    "    self.enableLearn = False\n",
    "    self.tableSize  = reflexSize\n",
    "    self.historyRM = []\n",
    "    self.historyTM = []\n",
    "    self.historyGT = []\n",
    "    self.entriesDeletedCount = 0\n",
    "    self.entriesPredictedCount = 0\n",
    "\n",
    "  def add(self, denseColumns):\n",
    "    acKey1 = '-'.join(map(str, denseColumns.sparse))\n",
    "    if(self.acKey0 != None):\n",
    "\n",
    "      sequence = self.pairs.get(self.acKey0, {})\n",
    "      sequence_data = sequence.get(acKey1, {\n",
    "         \"count\": 0,\n",
    "         \"time\": datetime.now()\n",
    "      })\n",
    "      sequence_data[\"count\"] = sequence_data[\"count\"] + 1\n",
    "      sequence_data[\"time\"] = datetime.now()\n",
    "\n",
    "      if self.pairs.get(self.acKey0, None) is None:\n",
    "        self.pairs[self.acKey0] = { acKey1: sequence_data }\n",
    "      else:\n",
    "        self.pairs[self.acKey0][acKey1] = sequence_data\n",
    "\n",
    "      table_entries = 0\n",
    "      oldKey1 = None\n",
    "      oldKey2 = None\n",
    "      oldTime = datetime.now()\n",
    "      for key1, value1 in self.pairs.items():\n",
    "        table_entries = table_entries + len(value1.items())\n",
    "        for key2, value2 in value1.items():\n",
    "          if value2['time'] < oldTime:\n",
    "            oldKey1 = key1\n",
    "            oldKey2 = key2\n",
    "            oldTime = value2['time']\n",
    "      if table_entries > self.tableSize:\n",
    "        self.enableLearn = True\n",
    "        self.entriesDeletedCount = self.entriesDeletedCount + 1\n",
    "        del self.pairs[oldKey1][oldKey2]\n",
    "        if len(self.pairs[oldKey1].items()) == 0:\n",
    "          del self.pairs[oldKey1]\n",
    "\n",
    "    self.acKey0 = acKey1\n",
    "\n",
    "  def predict(self, denseColumns):\n",
    "    return_count = 0\n",
    "    return_sdr = None\n",
    "\n",
    "    acKey = '-'.join(map(str, denseColumns.sparse))\n",
    "    sequences = self.pairs.get(acKey, {})\n",
    "    for sequence_key, sequence_data in sequences.items():\n",
    "      if sequence_data[\"count\"] > return_count:\n",
    "        return_count = sequence_data[\"count\"]\n",
    "        return_sdr = sequence_key\n",
    "\n",
    "    if return_sdr is not None:\n",
    "      tmp_sdr = SDR( denseColumns.dimensions )\n",
    "      tmp_sdr.sparse = list(map(int, return_sdr.split('-')))\n",
    "      return_sdr = tmp_sdr\n",
    "    else:\n",
    "      return_count = None\n",
    "\n",
    "    return return_count, return_sdr\n",
    "\n",
    "  def learn(self, denseColumns1, sp, tm):\n",
    "\n",
    "    tm.activateDendrites(True)\n",
    "    predictiveColumns = SDR( tm.getPredictiveCells().dimensions[0] )\n",
    "    predictiveColumns.sparse = list(set(sorted(list(np.where(tm.getPredictiveCells().dense == 1)[0]))))\n",
    "\n",
    "    activeColumns1 = SDR( predictiveColumns.dimensions )\n",
    "    sp.compute(denseColumns1, False, activeColumns1)\n",
    "\n",
    "    denseColumns0 = SDR( denseColumns1.dimensions )\n",
    "    denseColumns0.sparse = list(map(int, self.acKey0.split('-')))\n",
    "    activeColumns0 = SDR( predictiveColumns.dimensions )\n",
    "    sp.compute(denseColumns0, False, activeColumns0)\n",
    " \n",
    "    reflexiveCount, denseReflexiveColumns = self.predict(denseColumns0)\n",
    "    reflexiveColumns = SDR( predictiveColumns.dimensions )\n",
    "    if denseReflexiveColumns is not None:\n",
    "      sp.compute(denseReflexiveColumns, False, reflexiveColumns)\n",
    "\n",
    "    self.entriesPredictedCount = self.entriesPredictedCount + 1\n",
    "\n",
    "    overlapRM = 1 - np.count_nonzero((reflexiveColumns.dense & activeColumns1.dense)) / np.count_nonzero(activeColumns1.dense)\n",
    "    self.anomalyRM.append( overlapRM )\n",
    "\n",
    "    overlapTM = 1 - np.count_nonzero((predictiveColumns.dense & activeColumns1.dense)) / np.count_nonzero(activeColumns1.dense)\n",
    "    self.anomalyTM.append( overlapTM )\n",
    "\n",
    "    self.historyRM.append( reflexiveColumns.dense )\n",
    "    self.historyTM.append( predictiveColumns.dense )\n",
    "    self.historyGT.append( activeColumns1.dense )\n",
    "\n",
    "  def compute(self, denseColumns, sp, tm):\n",
    "    if self.acKey0 is not None:\n",
    "      self.learn(denseColumns, sp, tm)  \n",
    "    self.add(denseColumns)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSources = [\n",
    "   \"monthly_sp500_pca.csv\",\n",
    "   \"weekly_dow_jones.csv\",\n",
    "   \"weekly_nasdaq.csv\",\n",
    "   \"weekly_sp500.csv\",\n",
    "   \"monthly_vix_close.csv\",\n",
    "   \"monthly_vix_high.csv\",\n",
    "   \"monthly_vix_low.csv\",\n",
    "   \"monthly_vix_open.csv\",\n",
    "   \"daily_natural_gas.csv\",\n",
    "   \"daily_oil_prices.csv\",\n",
    "   \"value1_vix_close.csv\",\n",
    "   \"value1_vix_high.csv\",\n",
    "   \"value1_vix_low.csv\",\n",
    "   \"value1_vix_open.csv\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    'enc': {\n",
    "        \"value\" :\n",
    "            {'resolution': 0.88, 'size': 700, 'sparsity': 0.02},\n",
    "        \"time\": \n",
    "            {'timeOfDay': (30, 1), 'weekend': 21}\n",
    "    },\n",
    "    'sp': {\n",
    "        'inputDimensions': None,\n",
    "        'columnDimensions': (1638,),\n",
    "        'potentialPct': 0.85,\n",
    "        'potentialRadius': None,\n",
    "        'globalInhibition': True,\n",
    "        'localAreaDensity': 0.04395604395604396,\n",
    "        'synPermInactiveDec': 0.006,\n",
    "        'synPermActiveInc': 0.04,\n",
    "        'synPermConnected': 0.13999999999999999,\n",
    "        'boostStrength': 3.0,\n",
    "        'wrapAround': True,\n",
    "        'seed': 1,\n",
    "        'learn': False,\n",
    "    },\n",
    "    'tm': {\n",
    "        'cellsPerColumn': 13,\n",
    "        'activationThreshold': 17,\n",
    "        'initialPermanence': 0.21,\n",
    "        'minThreshold': 10,\n",
    "        'maxNewSynapseCount': 32,\n",
    "        'permanenceIncrement': 0.1,\n",
    "        'permanenceDecrement': 0.1,\n",
    "        'predictedSegmentDecrement': 0.0,\n",
    "        'maxSegmentsPerCell': 128,\n",
    "        'maxSynapsesPerSegment': 64,\n",
    "        'learn': True\n",
    "    },\n",
    "    'anomaly': {'period': 1000},\n",
    "    'learnRows': 100,\n",
    "    'reflexSize': 2048\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalyScore(y, x):\n",
    "    if np.count_nonzero(y) != 0:\n",
    "        return 1 - np.count_nonzero((x & y)) / np.count_nonzero(y)\n",
    "    return 1\n",
    "\n",
    "def match(y, x, idx1):\n",
    "  overlap_min = 0.02\n",
    "  n_samples = len(y)\n",
    "  score1 = anomalyScore(y[idx1], x[idx1])\n",
    "  if score1 > (1 - overlap_min):\n",
    "     idx_closest = None\n",
    "     score_closest = None\n",
    "     for idx2 in range(n_samples):\n",
    "        score2 = anomalyScore(y[idx2], x[idx1])\n",
    "        if score_closest is None or score_closest > score2:\n",
    "            score_closest = score2\n",
    "            idx_closest = idx2\n",
    "     return idx_closest\n",
    "  return idx1\n",
    "\n",
    "def roc_auc_score_multiclass(y_true, y_pred):\n",
    "    scores = []\n",
    "    for y_class in set(y_true):\n",
    "        y_true_class = [True if x == y_class else False for x in y_true]\n",
    "        y_pred_class = [True if x == y_class else False for x in y_pred]\n",
    "        scores.append(roc_auc_score(y_true_class, y_pred_class))\n",
    "    return sum(scores) / len(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:37<00:00,  2.68s/it]\n"
     ]
    }
   ],
   "source": [
    "input_path = pathlib.Path('../datasets/numenta')\n",
    "dataset_metrics = []\n",
    "\n",
    "pbar = tqdm(total=len(inputSources))\n",
    "for dataset in inputSources:\n",
    "\n",
    "    tm_infer_tm = 0\n",
    "    tm_infer_rm = 0\n",
    "\n",
    "    records = []\n",
    "    with open(input_path.joinpath(dataset), \"r\") as fin:\n",
    "        reader = csv.reader(fin)\n",
    "        headers = next(reader)\n",
    "        next(reader)\n",
    "        next(reader)\n",
    "        for record in reader:\n",
    "            records.append(record)\n",
    "        \n",
    "    scalarEncoderParams = RDSE_Parameters()\n",
    "    scalarEncoderParams.size = config[\"enc\"][\"value\"][\"size\"]\n",
    "    scalarEncoderParams.sparsity = config[\"enc\"][\"value\"][\"sparsity\"]\n",
    "    scalarEncoderParams.resolution = config[\"enc\"][\"value\"][\"resolution\"]\n",
    "    scalarEncoder = RDSE( scalarEncoderParams )\n",
    "    encodingWidth = (scalarEncoder.size)\n",
    "\n",
    "    config['sp']['inputDimensions'] = (encodingWidth,)\n",
    "    config['sp']['potentialRadius'] = encodingWidth\n",
    "\n",
    "    sp = SpatialPooler(\n",
    "        inputDimensions = config['sp']['inputDimensions'],\n",
    "        columnDimensions = config['sp']['columnDimensions'],\n",
    "        potentialPct = config['sp']['potentialPct'],\n",
    "        potentialRadius = config['sp']['potentialRadius'],\n",
    "        globalInhibition = config['sp']['globalInhibition'],\n",
    "        localAreaDensity = config['sp']['localAreaDensity'],\n",
    "        synPermInactiveDec = config['sp']['synPermInactiveDec'],\n",
    "        synPermActiveInc = config['sp']['synPermActiveInc'],\n",
    "        synPermConnected = config['sp']['synPermConnected'],\n",
    "        boostStrength = config['sp']['boostStrength'],\n",
    "        wrapAround = config['sp']['wrapAround'],\n",
    "        seed = config['sp']['seed']\n",
    "    )\n",
    "\n",
    "    tm = TemporalMemory(\n",
    "        columnDimensions = config['sp']['columnDimensions'],\n",
    "        cellsPerColumn = config['tm']['cellsPerColumn'],\n",
    "        activationThreshold = config['tm']['activationThreshold'],\n",
    "        initialPermanence = config['tm']['initialPermanence'],\n",
    "        connectedPermanence = config['sp']['synPermConnected'],\n",
    "        minThreshold = config['tm']['minThreshold'],\n",
    "        maxNewSynapseCount = config['tm']['maxNewSynapseCount'],\n",
    "        permanenceIncrement = config['tm']['permanenceIncrement'],\n",
    "        permanenceDecrement = config['tm']['permanenceDecrement'],\n",
    "        predictedSegmentDecrement = config['tm']['predictedSegmentDecrement'],\n",
    "        maxSegmentsPerCell = config['tm']['maxSegmentsPerCell'],\n",
    "        maxSynapsesPerSegment = config['tm']['maxSynapsesPerSegment']\n",
    "    )\n",
    "\n",
    "    rm = ReflexiveMemory( config['reflexSize'] )\n",
    "\n",
    "    inputs = []\n",
    "   \n",
    "    try:\n",
    "        \n",
    "        for count, record in enumerate(records):\n",
    "\n",
    "            consumption = float(record[1])\n",
    "            inputs.append( consumption )\n",
    "            consumptionBits = scalarEncoder.encode(consumption)\n",
    "            encoding = SDR( consumptionBits )\n",
    "            \n",
    "            activeColumns = SDR( sp.getColumnDimensions() )\n",
    "\n",
    "            learn_sp = config['sp']['learn']\n",
    "            learn_tm = config['tm']['learn']\n",
    "            if count < config['learnRows']:\n",
    "                learn_sp = True\n",
    "                learn_tm = True\n",
    "\n",
    "            rm.compute(encoding, sp, tm)\n",
    "\n",
    "            sp.compute(encoding, learn_sp, activeColumns)\n",
    "\n",
    "            tmp_tm = time.time()\n",
    "            tm.compute(activeColumns, learn=learn_tm)\n",
    "            tm_infer_tm = tm_infer_tm + (time.time() - tmp_tm)\n",
    "\n",
    "            tmp_tm = time.time()\n",
    "            rm.predict(encoding)\n",
    "            tm_infer_rm = tm_infer_rm + (time.time() - tmp_tm)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(traceback.format_exc())\n",
    "        print(e)\n",
    "\n",
    "    metric = {}\n",
    "    metric['dataset'] = dataset\n",
    "    metric['rm-delete-count'] = rm.entriesDeletedCount\n",
    "    metric['rm-predict-count'] = rm.entriesPredictedCount\n",
    "    metric['inputt-count'] = len(inputs)\n",
    "\n",
    "    metric['key0-count'] = len(rm.pairs)\n",
    "    key1_max_value = -1\n",
    "    for key1, value1 in rm.pairs.items():\n",
    "        for key2, value2 in value1.items():\n",
    "            if key1_max_value < value2[\"count\"]:\n",
    "                key1_max_value = value2[\"count\"]\n",
    "    metric['key1-max-value'] = key1_max_value\n",
    "    metric['key-pair-max-len'] = max([ len(val0) for val0 in rm.pairs.values()])\n",
    "    metric['key-pair-counts'] = str([ len(val0) for val0 in rm.pairs.values()])\n",
    "\n",
    "    dataset_metrics.append(metric)\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>rm-delete-count</th>\n",
       "      <th>rm-predict-count</th>\n",
       "      <th>inputt-count</th>\n",
       "      <th>key0-count</th>\n",
       "      <th>key1-max-value</th>\n",
       "      <th>key-pair-max-len</th>\n",
       "      <th>key-pair-counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>monthly_sp500_pca.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>1641</td>\n",
       "      <td>1642</td>\n",
       "      <td>769</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>[6, 8, 8, 9, 8, 8, 8, 2, 5, 5, 6, 6, 4, 4, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weekly_dow_jones.csv</td>\n",
       "      <td>27</td>\n",
       "      <td>2079</td>\n",
       "      <td>2080</td>\n",
       "      <td>1823</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>[3, 3, 1, 2, 1, 2, 2, 2, 2, 2, 3, 2, 2, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weekly_nasdaq.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>2080</td>\n",
       "      <td>2081</td>\n",
       "      <td>1469</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>[4, 1, 3, 1, 1, 2, 4, 3, 3, 3, 1, 1, 1, 1, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weekly_sp500.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>2081</td>\n",
       "      <td>2082</td>\n",
       "      <td>1161</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>[6, 4, 3, 3, 2, 5, 2, 4, 2, 2, 4, 6, 7, 6, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>monthly_vix_close.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>4050</td>\n",
       "      <td>4051</td>\n",
       "      <td>72</td>\n",
       "      <td>224</td>\n",
       "      <td>14</td>\n",
       "      <td>[12, 8, 12, 10, 10, 13, 10, 13, 10, 9, 7, 8, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>monthly_vix_high.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>4050</td>\n",
       "      <td>4051</td>\n",
       "      <td>82</td>\n",
       "      <td>192</td>\n",
       "      <td>15</td>\n",
       "      <td>[10, 11, 9, 8, 10, 11, 10, 11, 12, 12, 8, 8, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>monthly_vix_low.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>4050</td>\n",
       "      <td>4051</td>\n",
       "      <td>70</td>\n",
       "      <td>241</td>\n",
       "      <td>13</td>\n",
       "      <td>[8, 11, 9, 8, 8, 10, 9, 9, 9, 7, 7, 5, 4, 10, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>monthly_vix_open.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>4050</td>\n",
       "      <td>4051</td>\n",
       "      <td>75</td>\n",
       "      <td>210</td>\n",
       "      <td>13</td>\n",
       "      <td>[11, 9, 8, 11, 8, 9, 11, 10, 11, 9, 9, 6, 4, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>daily_natural_gas.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>5798</td>\n",
       "      <td>5799</td>\n",
       "      <td>18</td>\n",
       "      <td>1392</td>\n",
       "      <td>6</td>\n",
       "      <td>[5, 6, 4, 3, 2, 6, 5, 4, 6, 5, 4, 5, 1, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>daily_oil_prices.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>8300</td>\n",
       "      <td>8301</td>\n",
       "      <td>151</td>\n",
       "      <td>372</td>\n",
       "      <td>11</td>\n",
       "      <td>[5, 5, 6, 5, 3, 4, 3, 3, 4, 4, 4, 3, 4, 6, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>value1_vix_close.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>4049</td>\n",
       "      <td>4050</td>\n",
       "      <td>72</td>\n",
       "      <td>224</td>\n",
       "      <td>14</td>\n",
       "      <td>[8, 12, 12, 10, 10, 13, 10, 13, 10, 9, 7, 8, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>value1_vix_high.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>4049</td>\n",
       "      <td>4050</td>\n",
       "      <td>82</td>\n",
       "      <td>192</td>\n",
       "      <td>15</td>\n",
       "      <td>[11, 9, 10, 8, 10, 11, 10, 11, 12, 12, 8, 8, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>value1_vix_low.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>4049</td>\n",
       "      <td>4050</td>\n",
       "      <td>70</td>\n",
       "      <td>241</td>\n",
       "      <td>13</td>\n",
       "      <td>[11, 9, 8, 8, 8, 10, 9, 9, 9, 7, 7, 5, 4, 10, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>value1_vix_open.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>4049</td>\n",
       "      <td>4050</td>\n",
       "      <td>75</td>\n",
       "      <td>210</td>\n",
       "      <td>13</td>\n",
       "      <td>[9, 8, 11, 8, 11, 9, 11, 10, 11, 9, 9, 6, 4, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset  rm-delete-count  rm-predict-count  inputt-count  \\\n",
       "0   monthly_sp500_pca.csv                0              1641          1642   \n",
       "1    weekly_dow_jones.csv               27              2079          2080   \n",
       "2       weekly_nasdaq.csv                0              2080          2081   \n",
       "3        weekly_sp500.csv                0              2081          2082   \n",
       "4   monthly_vix_close.csv                0              4050          4051   \n",
       "5    monthly_vix_high.csv                0              4050          4051   \n",
       "6     monthly_vix_low.csv                0              4050          4051   \n",
       "7    monthly_vix_open.csv                0              4050          4051   \n",
       "8   daily_natural_gas.csv                0              5798          5799   \n",
       "9    daily_oil_prices.csv                0              8300          8301   \n",
       "10   value1_vix_close.csv                0              4049          4050   \n",
       "11    value1_vix_high.csv                0              4049          4050   \n",
       "12     value1_vix_low.csv                0              4049          4050   \n",
       "13    value1_vix_open.csv                0              4049          4050   \n",
       "\n",
       "    key0-count  key1-max-value  key-pair-max-len  \\\n",
       "0          769               4                11   \n",
       "1         1823               2                 4   \n",
       "2         1469               3                 7   \n",
       "3         1161               4                 7   \n",
       "4           72             224                14   \n",
       "5           82             192                15   \n",
       "6           70             241                13   \n",
       "7           75             210                13   \n",
       "8           18            1392                 6   \n",
       "9          151             372                11   \n",
       "10          72             224                14   \n",
       "11          82             192                15   \n",
       "12          70             241                13   \n",
       "13          75             210                13   \n",
       "\n",
       "                                      key-pair-counts  \n",
       "0   [6, 8, 8, 9, 8, 8, 8, 2, 5, 5, 6, 6, 4, 4, 6, ...  \n",
       "1   [3, 3, 1, 2, 1, 2, 2, 2, 2, 2, 3, 2, 2, 1, 1, ...  \n",
       "2   [4, 1, 3, 1, 1, 2, 4, 3, 3, 3, 1, 1, 1, 1, 3, ...  \n",
       "3   [6, 4, 3, 3, 2, 5, 2, 4, 2, 2, 4, 6, 7, 6, 4, ...  \n",
       "4   [12, 8, 12, 10, 10, 13, 10, 13, 10, 9, 7, 8, 9...  \n",
       "5   [10, 11, 9, 8, 10, 11, 10, 11, 12, 12, 8, 8, 9...  \n",
       "6   [8, 11, 9, 8, 8, 10, 9, 9, 9, 7, 7, 5, 4, 10, ...  \n",
       "7   [11, 9, 8, 11, 8, 9, 11, 10, 11, 9, 9, 6, 4, 1...  \n",
       "8   [5, 6, 4, 3, 2, 6, 5, 4, 6, 5, 4, 5, 1, 5, 5, ...  \n",
       "9   [5, 5, 6, 5, 3, 4, 3, 3, 4, 4, 4, 3, 4, 6, 5, ...  \n",
       "10  [8, 12, 12, 10, 10, 13, 10, 13, 10, 9, 7, 8, 9...  \n",
       "11  [11, 9, 10, 8, 10, 11, 10, 11, 12, 12, 8, 8, 9...  \n",
       "12  [11, 9, 8, 8, 8, 10, 9, 9, 9, 7, 7, 5, 4, 10, ...  \n",
       "13  [9, 8, 11, 8, 11, 9, 11, 10, 11, 9, 9, 6, 4, 1...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset_metrics)\n",
    "df.to_csv('metrics.csv', index=False)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
